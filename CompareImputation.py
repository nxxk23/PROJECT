# -*- coding: utf-8 -*-
"""Test_CompareImputation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/nxxk23/PROJECT/blob/main/Test_CompareImputation.ipynb
"""

!pip install missingpy
!pip install scikit-learn==1.1.2

import sklearn
print(sklearn.__version__)

from google.colab import drive
drive.mount('/content/drive')

"""**OriginalData**"""

import pandas as pd
widetable = pd.read_excel('/content/drive/MyDrive/ckdresearch2023/Assign/Wide Table/WideTable.xlsx')
widetable = widetable.iloc[:, 1:]
widetable.head()

df = widetable.copy()

"""**dummy**"""

widetable['Sex'] = widetable['Sex'].replace({'ชาย': 0, 'หญิง': 1})

nationality_map = {'ไทย': 0}

caucasian = ['บริติช  (อังกฤษ, สก็อตแลนด์)', 'อเมริกัน', 'เยอรมัน', 'โอมาน', 'ออสเตรเลีย', 'แคนาดา',
             'อิตาลี', 'สวิส', 'ซีเรีย', 'เดนมาร์ก', 'นอร์เวย์', 'ดัตช์', 'สเปน', 'เบลเยียม', 'ไอซ์แลนด์',
             'ฝรั่งเศส', 'เซนต์คิตส์และเนวิส', 'สวีเดน', 'ออสเตรีย', 'ไซปรัส']
asian = ['ลาว','จีน','เวียดนาม','เขมรอพยพ','ไทยลื้อ','ญี่ปุ่น', 'จีน(ไต้หวัน)']
other = ['ไม่ระบุ','อื่นๆ','ไร้สัญชาติ']

for nationality in asian:
    nationality_map[nationality] = 1

for nationality in caucasian:
    nationality_map[nationality] = 2

for nationality in other:
    nationality_map[nationality] = 3

widetable['NATNL'] = widetable['NATNL'].replace(nationality_map)

import numpy as np

widetable['LabLocation'] = np.where(widetable['LabLocation'] == "ห้องปฏิบัติการจุลทรรศน์วินิจฉัย", 1, 0)

df_no_missing = widetable.dropna()
df_no_missing= df_no_missing.reset_index(drop=True)
df_no_missing.shape

remove = ['Slopes', 'PatientUID', 'PatientVisitUID','InPatient', 'OutPatient', 'Emergency','eGFR_t1','time_t1', 'VisitLocation', 'StartDTTM','EndDttm', 'LabCwhen']
df_no_missing = df_no_missing.drop(columns=remove)
no_missing = df_no_missing.copy()

import pandas as pd
import numpy as np
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
from scipy import stats
import sklearn.neighbors._base
import sys
sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base
from missingpy import MissForest

"""**สุ่มค่าว่างในข้อมูล**"""

missing_percentage = widetable.isnull().mean()
missing_probabilities = missing_percentage / missing_percentage.sum()

import numpy as np
df_with_missing = no_missing.copy()
for column in df_with_missing.columns:
    num_missing = int(np.round(missing_percentage[column] * len(df_with_missing)))
    missing_indices = np.random.choice(len(df_with_missing), num_missing, replace=False)
    df_with_missing.loc[missing_indices, column] = np.nan

df_with_missing.info()

num_iterations = 50

mse_Mice = []
mape_Mice = []
mae_Mice = []

for _ in range(num_iterations):
    random_missing_indices = {}
    for column in df_with_missing.columns:
        num_missing = int(np.round(missing_probabilities[column] * len(df_with_missing)))
        random_missing_indices[column] = np.random.choice(len(df_with_missing), num_missing, replace=False)

    imputer_mice = IterativeImputer(random_state=0, initial_strategy='median')
    data_mice = df_with_missing.copy()
    for column in df_with_missing.columns:
        data_mice.loc[random_missing_indices[column], column] = np.nan

    data_mice_filled = imputer_mice.fit_transform(data_mice)
    Mice = pd.DataFrame(data_mice_filled, columns=data_mice.columns).round(1)

    # Calculate and append results for MICE
    mse_Mice.append(mean_squared_error(no_missing, Mice))
    true_values_mice = no_missing.values.flatten()
    imputed_values_mice = Mice.values.flatten()

    non_zero_mask_mice = true_values_mice != 0
    true_values_non_zero_mice = true_values_mice[non_zero_mask_mice]
    imputed_values_non_zero_mice = imputed_values_mice[non_zero_mask_mice]

    mape_Mice.append(np.mean(np.abs((true_values_non_zero_mice - imputed_values_non_zero_mice) / true_values_non_zero_mice)) * 100)
    mae_Mice.append(mean_absolute_error(no_missing, Mice))

mae_Mice

num_iterations = 50

mse_MF = []
mape_MF = []
mae_MF = []

for _ in range(num_iterations):
    random_missing_indices = {}
    for column in df_with_missing.columns:
        num_missing = int(np.round(missing_probabilities[column] * len(df_with_missing)))
        random_missing_indices[column] = np.random.choice(len(df_with_missing), num_missing, replace=False)

    imputer_missforest = MissForest(random_state=0, verbose=1)
    data_mf = df_with_missing.copy()
    for column in df_with_missing.columns:
        data_mf.loc[random_missing_indices[column], column] = np.nan

    data_mf_filled = imputer_missforest.fit_transform(data_mf)
    MF = pd.DataFrame(data_mf_filled, columns=data_mf.columns).round(1)

    # Calculate and append results for MF
    mse_MF.append(mean_squared_error(no_missing, MF))
    true_values_mf = no_missing.values.flatten()
    imputed_values_mf = MF.values.flatten()

    non_zero_mask_mf = true_values_mf != 0
    true_values_non_zero_mf = true_values_mf[non_zero_mask_mf]
    imputed_values_non_zero_mf = imputed_values_mf[non_zero_mask_mf]

    mape_MF.append(np.mean(np.abs((true_values_non_zero_mf - imputed_values_non_zero_mf) / true_values_non_zero_mf)) * 100)
    mae_MF.append(mean_absolute_error(no_missing, MF))

mse_Mice

mse_MF

mape_MF

mae_MF

"""**SimpleImpute**
```
* Mode = If the data type is 'object'.
* Mean = If the data type is numeric (not 'object') and dont have outlier
* Median = If the data type is numeric (not 'object') and have outlier
```
"""

df = widetable.copy()

# Repeat similar process for Simple Impute
columns_to_keep = ['PatientUID', 'PatientVisitUID', 'Slopes', 'InPatient', 'OutPatient', 'Emergency', 'eGFR_t1','time_t1', 'VisitLocation', 'StartDTTM', 'EndDttm', 'LabCwhen']
df_subset = df.loc[df_with_missing.index]
missing_for_binary = pd.concat([df_subset[columns_to_keep], df_with_missing], axis=1)

for column in df_with_missing.columns:
    missing_for_binary.loc[random_missing_indices[column], column] = np.nan

def detect_outliers(data, column):
    q1 = data[column].quantile(0.25)
    q3 = data[column].quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
    return not outliers.empty

columns_with_null = missing_for_binary.columns[missing_for_binary.isnull().any()].tolist()
imputed_table = missing_for_binary.copy()

def fill_missing_values(data, column, method):
    if method == 'mean':
        data[column].fillna(data[column].mean(), inplace=True)
    elif method == 'median':
        data[column].fillna(data[column].median(), inplace=True)
    elif method == 'mode':
        data[column].fillna(data[column].mode()[0], inplace=True)
    imputed_table = df_with_missing.copy()

num_iterations = 50

mse_simple = []
mae_simple = []
mape_simple = []

for _ in range(num_iterations):
    # Move the generation of random missing indices inside the loop
    random_missing_indices = {}
    for column in df_with_missing.columns:
        num_missing = int(np.round(missing_probabilities[column] * len(df_with_missing)))
        random_missing_indices[column] = np.random.choice(len(df_with_missing), num_missing, replace=False)

    imputed_table = missing_for_binary.copy()  # Make sure to copy the DataFrame

    for column in columns_with_null:
        if column in imputed_table.select_dtypes(include=['object']).columns:
            # Fill null values with a randomly chosen mode value for object columns
            mode_values = imputed_table[column].mode()
            imputed_table.loc[random_missing_indices[column], column] = np.random.choice(mode_values)
        elif column in imputed_table.select_dtypes(include=['float64']).columns:
            if detect_outliers(df_subset, column):
                # Median imputation for numeric columns with outliers
                median_values = df_subset.groupby('PatientVisitUID')[column].median()
                imputed_table.loc[random_missing_indices[column], column] = imputed_table.loc[random_missing_indices[column], 'PatientVisitUID'].map(median_values)
            else:
                # Mean imputation for numeric columns without outliers
                mean_values = df_subset.groupby('PatientVisitUID')[column].mean()
                imputed_table.loc[random_missing_indices[column], column] = imputed_table.loc[random_missing_indices[column], 'PatientVisitUID'].map(mean_values)

    # Check for outliers in each column and fill missing values accordingly
    for column in columns_with_null:
        outliers = detect_outliers(imputed_table, column)
        if imputed_table[column].dtype == 'object':
            imputed_table[column].fillna(imputed_table[column].mode()[0], inplace=True)
        elif not outliers:
            imputed_table[column].fillna(imputed_table[column].mean(), inplace=True)
        else:
            imputed_table[column].fillna(imputed_table[column].median(), inplace=True)

    # Drop columns if needed
    imputed_table = imputed_table.drop(columns=columns_to_keep)

    # Calculate and append results
    mse_simple.append(mean_squared_error(no_missing, imputed_table))
    true_values_simple = no_missing.values.flatten()
    imputed_values_simple = imputed_table.values.flatten()

    non_zero_mask_simple = true_values_simple != 0
    true_values_non_zero_simple = true_values_simple[non_zero_mask_simple]
    imputed_values_non_zero_simple = imputed_values_simple[non_zero_mask_simple]

    mape_simple.append(np.mean(np.abs((true_values_non_zero_simple - imputed_values_non_zero_simple) / true_values_non_zero_simple)) * 100)
    mae_simple.append(mean_absolute_error(no_missing, imputed_table))

mape_simple

"""#**Compare**


"""

import pandas as pd
import numpy as np

# Assuming you have the following results:
mae_results = {'MF': mae_MF, 'Mice': mae_Mice, 'Simple': mae_simple}
mse_results = {'MF': mse_MF, 'Mice': mse_Mice, 'Simple': mse_simple}
mape_results = {'MF': mape_MF, 'Mice': mape_Mice, 'Simple': mape_simple}

# Calculate means of the results
mean_mse_results = {method: np.mean(results) for method, results in mse_results.items()}
mean_mape_results = {method: np.mean(results) for method, results in mape_results.items()}
mean_mae_results = {method: np.mean(results) for method, results in mae_results.items()}

# Convert means to a DataFrame for easier printing
mean_evaluation_df = pd.DataFrame({
    'Method': list(mean_mse_results.keys()),
    'Mean MSE': list(mean_mse_results.values()),
    'Mean MAPE': list(mean_mape_results.values()),
    'Mean MAE': list(mean_mae_results.values())
})

mean_evaluation_df

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error

imputed_data = {'OriginalData': no_missing}
imputed_data['Mice'] = Mice
imputed_data['MissForest'] = MissForest
imputed_data['SimpleImpute'] = imputed_table